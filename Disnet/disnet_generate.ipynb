{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce2f2c8",
   "metadata": {},
   "source": [
    "### Generate dataset to be passed to disnet\n",
    "\n",
    "First import the classifier to classify traffic sign shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fc90ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\portierl4527\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\portierl4527\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\portierl4527\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 451,536\n",
      "Trainable params: 451,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = 'shape-classifier-aug.keras'\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "model = keras.models.load_model(classifier)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9571c7",
   "metadata": {},
   "source": [
    "### Create helper functions\n",
    "\n",
    "define paths for labels and images for train, val and test sets \\\n",
    "Functions to create masks and vectors from label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316ec61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "#construct val, train or test data\n",
    "def select_dataset(data):\n",
    "    \n",
    "    yolo_path = r'C:\\Users\\portierl4527\\ARCADIS\\Afstuderen Levi - Depth estimation - General\\yolov5\\yolov5-master\\runs\\detect'\n",
    "    img_path= r'C:\\Users\\portierl4527\\ARCADIS\\Afstuderen Levi - Depth estimation - General\\Cityscapes-Sequence\\leftImg8bit_sequence_trainvaltest'\n",
    "    \n",
    "    lab_path = os.path.join(yolo_path, data+'\\labels')\n",
    "    img_path = os.path.join(img_path, data)\n",
    "   \n",
    "    labels = glob.glob(lab_path+'\\*.txt')\n",
    "#     images = glob.glob(img_path+'\\*.png')\n",
    "    \n",
    "    return labels, img_path\n",
    "\n",
    "\n",
    "#ground truth file\n",
    "GT_PATH = r'C:\\Users\\portierl4527\\ARCADIS\\Afstuderen Levi - Depth estimation - General\\Cityscapes-Sequence\\disparity_sequence_trainvaltest\\gt_depth'\n",
    "gt_labels = glob.glob(GT_PATH+'\\*.npy')\n",
    "\n",
    "\n",
    "def transform2vector(class_id, x, y, w, h):\n",
    "    'takes yolo label as input and returns vector for disnet'\n",
    "    \n",
    "    dbbox = math.sqrt(w*w + h*h)\n",
    "    d= 1/(dbbox) #diagonal of bounding box /2289.7\n",
    "    w = 1/(w) #widht is 1/ (width/img size)\n",
    "    h = 1/(h) #height is 1/ (height/img size)\n",
    "     \n",
    "    class_id = int(class_id)\n",
    "    if class_id == 0:\n",
    "        cw = 60 #traffic signs width\n",
    "        ch = 60\n",
    "        cd = 5\n",
    "    else:\n",
    "        cw = 30\n",
    "        ch = 70 #traffic light height\n",
    "        cd = 25\n",
    "    \n",
    "    return class_id, w, h, d, cw, ch, cd\n",
    "\n",
    "\n",
    "def mask(x, y, w, h):\n",
    "    \"takes yolo label and creates mask of object\"\n",
    "    \n",
    "    width = 2048 #image size\n",
    "    height = 1024\n",
    "    \n",
    "    xmax = int((x*width) + (w * width)/2.0)\n",
    "    xmin = int((x*width) - (w * width)/2.0)\n",
    "    ymax = int((y*height) + (h * height)/2.0)\n",
    "    ymin = int((y*height) - (h * height)/2.0)\n",
    "    \n",
    "    return xmin, xmax, ymin, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d032b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1342/1342 [02:51<00:00,  7.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#set labels to train\n",
    "labels, IMAGE_PATH = select_dataset('low_quality')\n",
    "\n",
    "filename = []\n",
    "y_true = []\n",
    "object_id = []\n",
    "vector = []    \n",
    "bbox = []\n",
    "shape = []\n",
    "o_width = []\n",
    "o_height = []\n",
    " \n",
    "#for txt file in yolo labels    \n",
    "for file in tqdm(labels):\n",
    "    label_norm = np.loadtxt(file).reshape(-1, 5)\n",
    "    \n",
    "    basename = os.path.basename(file) #filename\n",
    "    basename_no_ext = os.path.splitext(basename)[0]\n",
    "    #[:-12]\n",
    "   \n",
    "    #for line in txt file\n",
    "    for i in range(len(label_norm)):\n",
    "        labels_conv = label_norm[i]\n",
    "        class_id, w, h, d, cw, ch, cd = transform2vector(labels_conv[0], labels_conv[1], labels_conv[2], labels_conv[3], labels_conv[4])\n",
    "        xmin, xmax, ymin, ymax =  mask(labels_conv[1], labels_conv[2], labels_conv[3], labels_conv[4])\n",
    "        \n",
    "        object_id.append(class_id) #append classID\n",
    "        #vector.append(np.array([w,h,d,cw,ch,cd])) #create the vector\n",
    "        filename.append(basename_no_ext) #add_filename\n",
    "        bbox.append([xmin, xmax, ymin, ymax])\n",
    "        o_width.append(xmax-xmin)\n",
    "        o_height.append(ymax-ymin)\n",
    "        \n",
    "        #if object is a traffic sign\n",
    "        if class_id == 0:\n",
    "            \n",
    "            #find corresponding image\n",
    "            img = os.path.join(IMAGE_PATH,'{}.png'.format(basename_no_ext))\n",
    "            img_array = cv2.imread(img, cv2.IMREAD_GRAYSCALE)#read image in grayscale\n",
    "            img_array = img_array[ymin:ymax,xmin:xmax] #mask the object\n",
    "\n",
    "            new_array = cv2.resize(img_array, (28,28)) #resize the object\n",
    "            X = np.array(new_array).reshape(-1, 28, 28, 1) #reshape the object\n",
    "\n",
    "            pred_shape = model.predict_classes(X) #predict the class\n",
    "            shape.append(pred_shape) #add to list\n",
    "\n",
    "            if pred_shape == 4: \n",
    "                vector.append(np.array([w,h,d,76,76,5])) #triangular signs\n",
    "            elif pred_shape == 3:\n",
    "                vector.append(np.array([w,h,d,51,51,5])) #square signs\n",
    "            else:\n",
    "                vector.append(np.array([w,h,d,52,52,5])) #other signs\n",
    "\n",
    "\n",
    "        #if object is a traffic light        \n",
    "        else:\n",
    "            vector.append(np.array([w,h,d,cw,ch,cd]))\n",
    "            shape.append(99)\n",
    "                \n",
    "        #search for corresponding ground truth file\n",
    "        gt = os.path.join(GT_PATH,'{}_disparity.npy'.format(basename_no_ext[:-4]))      \n",
    "        object_gt = np.load(gt)\n",
    "            \n",
    "        y_true.append(np.median(object_gt[ymin:ymax,xmin:xmax])) #add the true distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375da5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>object_id</th>\n",
       "      <th>y_true</th>\n",
       "      <th>vectors</th>\n",
       "      <th>o_width</th>\n",
       "      <th>o_height</th>\n",
       "      <th>shape</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonn_000000_000001_low</td>\n",
       "      <td>0</td>\n",
       "      <td>36.790001</td>\n",
       "      <td>[73.14272339616294, 42.666666666666664, 36.854...</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1141, 1169, 350, 374]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bonn_000000_000002_low</td>\n",
       "      <td>0</td>\n",
       "      <td>35.660000</td>\n",
       "      <td>[75.85181589247246, 39.38465416335179, 34.9537...</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1145, 1172, 346, 372]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bonn_000000_000008_low</td>\n",
       "      <td>0</td>\n",
       "      <td>30.040001</td>\n",
       "      <td>[68.26684142978073, 34.133304206247075, 30.529...</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1190, 1220, 288, 319]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bonn_000000_000009_low</td>\n",
       "      <td>0</td>\n",
       "      <td>29.610001</td>\n",
       "      <td>[66.0645979638891, 32.0, 28.7994091416293, 52....</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1196, 1227, 284, 316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bonn_000000_000012_low</td>\n",
       "      <td>0</td>\n",
       "      <td>26.370001</td>\n",
       "      <td>[58.51443551124063, 30.117669735657213, 26.778...</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1227, 1262, 267, 301]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  object_id     y_true  \\\n",
       "0  bonn_000000_000001_low          0  36.790001   \n",
       "1  bonn_000000_000002_low          0  35.660000   \n",
       "2  bonn_000000_000008_low          0  30.040001   \n",
       "3  bonn_000000_000009_low          0  29.610001   \n",
       "4  bonn_000000_000012_low          0  26.370001   \n",
       "\n",
       "                                             vectors  o_width  o_height shape  \\\n",
       "0  [73.14272339616294, 42.666666666666664, 36.854...       28        24   [0]   \n",
       "1  [75.85181589247246, 39.38465416335179, 34.9537...       27        26   [0]   \n",
       "2  [68.26684142978073, 34.133304206247075, 30.529...       30        31   [2]   \n",
       "3  [66.0645979638891, 32.0, 28.7994091416293, 52....       31        32   [0]   \n",
       "4  [58.51443551124063, 30.117669735657213, 26.778...       35        34   [2]   \n",
       "\n",
       "                     bbox  \n",
       "0  [1141, 1169, 350, 374]  \n",
       "1  [1145, 1172, 346, 372]  \n",
       "2  [1190, 1220, 288, 319]  \n",
       "3  [1196, 1227, 284, 316]  \n",
       "4  [1227, 1262, 267, 301]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "data = {'filename': filename,\n",
    "       'object_id': object_id,\n",
    "       'y_true': y_true,\n",
    "       'vectors': vector,\n",
    "       'o_width': o_width,\n",
    "       'o_height': o_height,\n",
    "       'shape': shape,\n",
    "       'bbox': bbox}\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "#only keep smaller than 60 meters\n",
    "df = df[df.y_true < 60.0]\n",
    "\n",
    "#drop wrong traffic signs\n",
    "wrong_size = df[ (df.object_id == 0) & (df.o_width > 2*df.o_height) ].index\n",
    "also_wrong_size = df[ (df.object_id == 0) & (df.o_height > 2*df.o_width) ].index\n",
    "\n",
    "df.drop(wrong_size, inplace=True)\n",
    "df.drop(also_wrong_size, inplace=True)\n",
    "\n",
    "\n",
    "#df.to_pickle('train_data4disnet.pkl')\n",
    "\n",
    "\n",
    "#df.to_pickle('test_data4disnet.pkl')\n",
    "\n",
    "\n",
    "df.to_pickle('low_data4disnet.pkl')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "434d6107",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a56cdde21821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mo_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m#plt.scatter(x=df.y_true, y=(diagonal))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#plt.scatter(x=light_data.y_true, y=(light_w), label = 'lights')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\portierl4527\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas-1.1.4-py3.7-win-amd64.egg\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'absolute_error'"
     ]
    }
   ],
   "source": [
    "#create plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#df containing signs and lights\n",
    "sign_data = df[df.object_id == 0]\n",
    "light_data  = df[df.object_id == 1] \n",
    "\n",
    "#index of rows\n",
    "signs  = df.index[df['object_id'] == 0].to_list()\n",
    "lights = df.index[df['object_id'] == 1].to_list()\n",
    "\n",
    "#all widths, heights and diagonals\n",
    "width = [vector[i][0] for i in range(len(vector))]\n",
    "height = [vector[i][1] for i in range(len(vector))]\n",
    "diagonal = [vector[i][2] for i in range(len(vector))]\n",
    "\n",
    "\n",
    "plt.scatter(x=df.o_height, y=df.absolute_error)\n",
    "#plt.scatter(x=df.y_true, y=(diagonal))\n",
    "#plt.scatter(x=light_data.y_true, y=(light_w), label = 'lights')\n",
    "plt.title('Distance vs 1/width')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
