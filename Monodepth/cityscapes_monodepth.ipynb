{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spare-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on gpu\n"
     ]
    }
   ],
   "source": [
    "### this scripts loads an image and predicts the depth\n",
    "from __future__ import absolute_import, division, print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import PIL.Image as pil\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import networks\n",
    "from utils import download_model_if_doesnt_exist\n",
    "import evaluate_depth\n",
    "from layers import disp_to_depth\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('running on gpu')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mono_1024x320\"\n",
    "\n",
    "download_model_if_doesnt_exist(model_name)\n",
    "encoder_path = os.path.join(\"models\", model_name, \"encoder.pth\")\n",
    "depth_decoder_path = os.path.join(\"models\", model_name, \"depth.pth\")\n",
    "\n",
    "# LOADING PRETRAINED MODEL\n",
    "encoder = networks.ResnetEncoder(18, False)\n",
    "depth_decoder = networks.DepthDecoder(num_ch_enc=encoder.num_ch_enc, scales=range(4))\n",
    "\n",
    "loaded_dict_enc = torch.load(encoder_path, map_location=device)\n",
    "filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}\n",
    "encoder.load_state_dict(filtered_dict_enc)\n",
    "encoder.to(device)\n",
    "\n",
    "loaded_dict = torch.load(depth_decoder_path, map_location=device)\n",
    "depth_decoder.load_state_dict(loaded_dict)\n",
    "\n",
    "encoder.eval()\n",
    "depth_decoder.to(device)\n",
    "depth_decoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arranged-chuck",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2100/2100 [06:55<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# validation data\n",
    "IMAGE_PATH = r'C:\\Users\\portierl4527\\ARCADIS\\Afstuderen Levi - Depth estimation - General\\Cityscapes-Sequence\\leftImg8bit_sequence_trainvaltest\\test'\n",
    "images = glob.glob(IMAGE_PATH+'\\*.png')\n",
    "\n",
    "\n",
    "# #train data\n",
    "# IMAGE_PATH = \"C:/Users/portierl4527/ARCADIS/Afstuderen Levi - Depth estimation - General/Cityscapes-Dataset/01_Prepared_Data/images/train\"\n",
    "# images = glob.glob(IMAGE_PATH+'\\*.png')\n",
    "\n",
    "\n",
    "#Preparing image\n",
    "for i in tqdm(images):\n",
    "\n",
    "    input_image = pil.open(i).convert('RGB')\n",
    "    original_width, original_height = input_image.size\n",
    "\n",
    "    feed_height = loaded_dict_enc['height']\n",
    "    feed_width = loaded_dict_enc['width']\n",
    "    input_image_resized = input_image.resize((feed_width, feed_height), pil.LANCZOS)\n",
    "\n",
    "    input_image_pytorch = transforms.ToTensor()(input_image_resized).unsqueeze(0)\n",
    "    input_image=input_image_pytorch.to(device)\n",
    "    \n",
    "    #prediction using monodepth\n",
    "    with torch.no_grad():\n",
    "        features = encoder(input_image)\n",
    "        outputs = depth_decoder(features)\n",
    "        \n",
    "        disp = outputs[(\"disp\", 0)]\n",
    "        \n",
    "        \n",
    "    #convert back to original size\n",
    "    disp_resized = torch.nn.functional.interpolate(disp,\n",
    "    (original_height, original_width), mode=\"bilinear\", align_corners=False)\n",
    "    \n",
    "    \n",
    "    scaled_disp, depth = disp_to_depth(disp_resized, 0.1, 100) #inverse depth and depth\n",
    "    \n",
    "    \n",
    "    disp_resized_np = depth.squeeze().cpu().numpy()\n",
    "    \n",
    "    #name for storing\n",
    "    basename = os.path.basename(i)\n",
    "    basename_no_ext = os.path.splitext(basename)[0]\n",
    "    \n",
    "    #save the numpy file\n",
    "    savepath= r\"C:\\Users\\portierl4527\\ARCADIS\\Afstuderen Levi - Depth estimation - General\\Cityscapes-Dataset\\monodepth\\cityscapes_prediction\\high\"\n",
    "     \n",
    "    \n",
    "    np.save(savepath +'/' + basename_no_ext + '_mono.npy', disp_resized_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1df6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
